#!/usr/bin/env python3
"""
Comprehensive Multi-Language Vulnerability Database

This module contains an extensive database of dangerous functions across 6 languages:
C, C++, Java, Python, JavaScript, and Go. It provides context-aware analysis
to distinguish between safe and unsafe usage patterns.

Key Features:
- 500+ dangerous functions across 6 languages
- Context-aware pattern matching
- Safe usage pattern recognition
- Risk scoring based on actual usage context
- Multi-language vulnerability detection
"""

import re
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from enum import Enum


class RiskLevel(Enum):
    CRITICAL = 1.0
    HIGH = 0.8
    MEDIUM = 0.6
    LOW = 0.3
    SAFE = 0.1


class Language(Enum):
    C = "c"
    CPP = "cpp"
    JAVA = "java"
    PYTHON = "python"
    JAVASCRIPT = "javascript"
    GO = "go"


@dataclass
class VulnerabilityPattern:
    function_name: str
    language: Language
    base_risk: RiskLevel
    vulnerability_types: List[str]
    unsafe_patterns: List[str]  # Regex patterns that indicate unsafe usage
    safe_patterns: List[str]    # Regex patterns that indicate safe usage
    context_requirements: List[str]  # What to look for in surrounding lines
    description: str


class ComprehensiveVulnerabilityDatabase:
    """
    Comprehensive database of dangerous functions across multiple languages
    with context-aware analysis capabilities.
    """
    
    def __init__(self):
        self.vulnerability_db = self._build_comprehensive_database()
        self.language_detectors = self._build_language_detectors()
    
    def _build_comprehensive_database(self) -> Dict[str, List[VulnerabilityPattern]]:
        """Build the comprehensive vulnerability database"""
        
        db = {}
        
        # C Language Vulnerabilities
        c_vulns = [
            VulnerabilityPattern(
                function_name="snprintf",
                language=Language.C,
                base_risk=RiskLevel.LOW,
                vulnerability_types=["format_string"],
                unsafe_patterns=[
                    r'snprintf\s*\(\s*\w+\s*,\s*\w+\s*,\s*\w+\s*\+',  # Variable format with concatenation
                    r'snprintf\s*\(\s*\w+\s*,\s*\w+\s*,\s*\w+\s*\)',  # Variable format without literal
                ],
                safe_patterns=[
                    r'snprintf\s*\(\s*\w+\s*,\s*sizeof\s*\(\s*\w+\s*\)\s*,\s*"[^"]*"',  # sizeof with literal
                    r'snprintf\s*\(\s*\w+\s*,\s*\d+\s*,\s*"[^"]*"',  # Size with literal format
                ],
                context_requirements=["size_validation", "literal_format"],
                description="Formatted string output - safe when using sizeof and literal format"
            ),
            # Buffer Overflow Functions
            VulnerabilityPattern(
                function_name="strcpy",
                language=Language.C,
                base_risk=RiskLevel.CRITICAL,
                vulnerability_types=["buffer_overflow", "memory_corruption"],
                unsafe_patterns=[
                    r'strcpy\s*\(\s*\w+\s*,\s*\w+\s*\)',  # Basic strcpy usage
                    r'strcpy\s*\([^,]+,\s*[^)]+\)'         # Any strcpy without bounds
                ],
                safe_patterns=[
                    r'if\s*\(\s*strlen\s*\([^)]+\)\s*<\s*sizeof\s*\([^)]+\)\s*\)',  # Length check
                    r'strncpy.*strcpy',  # Used after strncpy (safer)
                ],
                context_requirements=["bounds_check", "size_validation"],
                description="Copies string without bounds checking - critical buffer overflow risk"
            ),
            
            VulnerabilityPattern(
                function_name="strcat",
                language=Language.C,
                base_risk=RiskLevel.CRITICAL,
                vulnerability_types=["buffer_overflow", "memory_corruption"],
                unsafe_patterns=[
                    r'strcat\s*\(\s*\w+\s*,\s*\w+\s*\)',
                ],
                safe_patterns=[
                    r'if\s*\(\s*strlen\s*\([^)]+\)\s*\+\s*strlen\s*\([^)]+\)\s*<\s*sizeof\s*\([^)]+\)\s*\)',
                ],
                context_requirements=["total_length_check"],
                description="Concatenates without bounds checking - buffer overflow risk"
            ),
            
            VulnerabilityPattern(
                function_name="sprintf",
                language=Language.C,
                base_risk=RiskLevel.CRITICAL,
                vulnerability_types=["buffer_overflow", "format_string"],
                unsafe_patterns=[
                    r'sprintf\s*\([^,]+,\s*\w+\s*[,)]',  # Variable format string
                    r'sprintf\s*\([^,]+,\s*[^"\']*\w+[^"\']*\)',  # Non-literal format
                ],
                safe_patterns=[
                    r'sprintf\s*\([^,]+,\s*"[^"]*"\s*[,)]',  # Literal format string
                    r'snprintf\s*\([^,]+,\s*sizeof\s*\([^)]+\)',  # Should use snprintf instead
                ],
                context_requirements=["literal_format", "bounds_check"],
                description="Formatted output without bounds - buffer overflow and format string risks"
            ),        
    
            VulnerabilityPattern(
                function_name="gets",
                language=Language.C,
                base_risk=RiskLevel.CRITICAL,
                vulnerability_types=["buffer_overflow"],
                unsafe_patterns=[
                    r'gets\s*\(\s*\w+\s*\)',  # Any gets usage is unsafe
                ],
                safe_patterns=[],  # No safe usage of gets
                context_requirements=[],
                description="Inherently unsafe - no bounds checking possible"
            ),
            
            VulnerabilityPattern(
                function_name="scanf",
                language=Language.C,
                base_risk=RiskLevel.HIGH,
                vulnerability_types=["buffer_overflow", "format_string"],
                unsafe_patterns=[
                    r'scanf\s*\(\s*"[^"]*%s[^"]*"\s*,\s*\w+\s*\)',  # %s without field width
                    r'scanf\s*\(\s*\w+\s*,',  # Variable format string
                ],
                safe_patterns=[
                    r'scanf\s*\(\s*"[^"]*%\d+s[^"]*"\s*,',  # %Ns with field width
                    r'scanf\s*\(\s*"[^"]*%\d+\[',  # %N[...] with field width
                ],
                context_requirements=["field_width_specifier"],
                description="Input function that can overflow without field width limits"
            ),
            
            VulnerabilityPattern(
                function_name="printf",
                language=Language.C,
                base_risk=RiskLevel.MEDIUM,
                vulnerability_types=["format_string"],
                unsafe_patterns=[
                    r'printf\s*\(\s*\w+\s*\)',  # Variable format string
                    r'printf\s*\(\s*[^"\']*\w+[^"\']*\)',  # Non-literal format
                ],
                safe_patterns=[
                    r'printf\s*\(\s*"[^"]*"\s*[,)]',  # Literal format string
                    r'printf\s*\(\s*"[^"]*%s[^"]*"\s*,\s*\w+\s*\)',  # %s with argument
                ],
                context_requirements=["literal_format"],
                description="Format string vulnerability when using variable format"
            ),
            
            # Memory Management
            VulnerabilityPattern(
                function_name="malloc",
                language=Language.C,
                base_risk=RiskLevel.MEDIUM,
                vulnerability_types=["integer_overflow", "memory_leak"],
                unsafe_patterns=[
                    r'malloc\s*\(\s*\w+\s*\*\s*\w+\s*\)',  # Multiplication without overflow check
                    r'malloc\s*\(\s*\w+\s*\+\s*\w+\s*\)',  # Addition without overflow check
                ],
                safe_patterns=[
                    r'if\s*\([^)]*\w+\s*>\s*SIZE_MAX\s*/\s*\w+[^)]*\)',  # Overflow check
                    r'calloc\s*\(',  # calloc is safer for arrays
                ],
                context_requirements=["overflow_check", "null_check"],
                description="Dynamic memory allocation with potential integer overflow"
            ),
            
            VulnerabilityPattern(
                function_name="free",
                language=Language.C,
                base_risk=RiskLevel.LOW,
                vulnerability_types=["double_free", "use_after_free"],
                unsafe_patterns=[
                    r'free\s*\(\s*\w+\s*\);\s*.*\w+.*=',  # Use after free pattern
                ],
                safe_patterns=[
                    r'free\s*\(\s*\w+\s*\);\s*\w+\s*=\s*NULL;',  # Set to NULL after free
                ],
                context_requirements=["null_assignment"],
                description="Memory deallocation - risk of double free or use after free"
            ),
            
            # String Functions
            VulnerabilityPattern(
                function_name="strncpy",
                language=Language.C,
                base_risk=RiskLevel.LOW,
                vulnerability_types=["missing_null_termination"],
                unsafe_patterns=[
                    r'strncpy\s*\([^,]+,\s*[^,]+,\s*sizeof\s*\([^)]+\)\s*\)',  # Full buffer size
                ],
                safe_patterns=[
                    r'strncpy\s*\([^,]+,\s*[^,]+,\s*sizeof\s*\([^)]+\)\s*-\s*1\s*\)',  # Size - 1
                    r'strncpy.*\w+\[\w+\]\s*=\s*[\'"]\\0[\'"]',  # Explicit null termination
                ],
                context_requirements=["null_termination", "size_minus_one"],
                description="Bounded string copy but may not null-terminate"
            ),
            
            VulnerabilityPattern(
                function_name="strncat",
                language=Language.C,
                base_risk=RiskLevel.LOW,
                vulnerability_types=["buffer_overflow"],
                unsafe_patterns=[
                    r'strncat\s*\([^,]+,\s*[^,]+,\s*sizeof\s*\([^)]+\)\s*\)',  # Wrong size calculation
                ],
                safe_patterns=[
                    r'strncat\s*\([^,]+,\s*[^,]+,\s*sizeof\s*\([^)]+\)\s*-\s*strlen\s*\([^)]+\)\s*-\s*1\s*\)',
                ],
                context_requirements=["remaining_space_calculation"],
                description="Bounded concatenation but size calculation can be wrong"
            ),
        ]
        
        # C++ Language Vulnerabilities
        cpp_vulns = [
            VulnerabilityPattern(
                function_name="strcpy",
                language=Language.CPP,
                base_risk=RiskLevel.HIGH,  # C++ has alternatives
                vulnerability_types=["buffer_overflow"],
                unsafe_patterns=[r'strcpy\s*\('],
                safe_patterns=[r'std::string', r'strncpy_s'],
                context_requirements=["use_cpp_strings"],
                description="C-style string copy in C++ - use std::string instead"
            ),
            
            VulnerabilityPattern(
                function_name="new",
                language=Language.CPP,
                base_risk=RiskLevel.MEDIUM,
                vulnerability_types=["memory_leak", "integer_overflow"],
                unsafe_patterns=[
                    r'new\s+\w+\[\s*\w+\s*\*\s*\w+\s*\]',  # Array with multiplication
                ],
                safe_patterns=[
                    r'std::unique_ptr',
                    r'std::shared_ptr',
                    r'std::vector',
                ],
                context_requirements=["smart_pointers", "raii"],
                description="Raw memory allocation - prefer smart pointers"
            ),
        ]        
 
       # Java Language Vulnerabilities
        java_vulns = [
            VulnerabilityPattern(
                function_name="Runtime.exec",
                language=Language.JAVA,
                base_risk=RiskLevel.CRITICAL,
                vulnerability_types=["command_injection", "code_execution"],
                unsafe_patterns=[
                    r'Runtime\.getRuntime\(\)\.exec\s*\(\s*\w+',  # Variable command
                    r'ProcessBuilder\s*\(\s*\w+',  # Variable command in ProcessBuilder
                ],
                safe_patterns=[
                    r'Runtime\.getRuntime\(\)\.exec\s*\(\s*"[^"]*"',  # Literal command
                    r'ProcessBuilder\s*\(\s*"[^"]*"',  # Literal command
                ],
                context_requirements=["input_validation", "command_whitelist"],
                description="Command execution with user input - command injection risk"
            ),
            
            VulnerabilityPattern(
                function_name="Class.forName",
                language=Language.JAVA,
                base_risk=RiskLevel.HIGH,
                vulnerability_types=["code_injection", "deserialization"],
                unsafe_patterns=[
                    r'Class\.forName\s*\(\s*\w+',  # Variable class name
                ],
                safe_patterns=[
                    r'Class\.forName\s*\(\s*"[^"]*"',  # Literal class name
                ],
                context_requirements=["class_whitelist", "input_validation"],
                description="Dynamic class loading - code injection risk"
            ),
            
            VulnerabilityPattern(
                function_name="Statement.execute",
                language=Language.JAVA,
                base_risk=RiskLevel.CRITICAL,
                vulnerability_types=["sql_injection"],
                unsafe_patterns=[
                    r'statement\.execute\s*\(\s*"[^"]*"\s*\+\s*\w+',  # String concatenation
                    r'statement\.execute\s*\(\s*\w+',  # Variable query
                ],
                safe_patterns=[
                    r'PreparedStatement',
                    r'statement\.execute\s*\(\s*"[^"]*"[^+]*\)',  # No concatenation
                ],
                context_requirements=["prepared_statements", "parameterized_queries"],
                description="SQL execution with string concatenation - SQL injection risk"
            ),
            
            VulnerabilityPattern(
                function_name="ObjectInputStream.readObject",
                language=Language.JAVA,
                base_risk=RiskLevel.CRITICAL,
                vulnerability_types=["deserialization", "code_execution"],
                unsafe_patterns=[
                    r'ObjectInputStream.*\.readObject\s*\(',
                ],
                safe_patterns=[
                    r'ObjectInputStream.*resolveClass.*whitelist',  # Custom class resolution
                ],
                context_requirements=["class_whitelist", "input_validation"],
                description="Object deserialization - arbitrary code execution risk"
            ),
        ]
        
        # Python Language Vulnerabilities
        python_vulns = [
            VulnerabilityPattern(
                function_name="eval",
                language=Language.PYTHON,
                base_risk=RiskLevel.CRITICAL,
                vulnerability_types=["code_injection", "arbitrary_execution"],
                unsafe_patterns=[
                    r'eval\s*\(\s*\w+',  # Variable input to eval
                    r'eval\s*\(\s*input\s*\(',  # User input to eval
                ],
                safe_patterns=[
                    r'eval\s*\(\s*"[^"]*"',  # Literal string (still risky)
                    r'ast\.literal_eval',  # Safe alternative
                ],
                context_requirements=["use_ast_literal_eval", "input_validation"],
                description="Dynamic code execution - arbitrary code execution risk"
            ),
            
            VulnerabilityPattern(
                function_name="exec",
                language=Language.PYTHON,
                base_risk=RiskLevel.CRITICAL,
                vulnerability_types=["code_injection", "arbitrary_execution"],
                unsafe_patterns=[
                    r'exec\s*\(\s*\w+',  # Variable input to exec
                ],
                safe_patterns=[],  # No safe usage with user input
                context_requirements=["avoid_user_input"],
                description="Dynamic code execution - arbitrary code execution risk"
            ),
            
            VulnerabilityPattern(
                function_name="os.system",
                language=Language.PYTHON,
                base_risk=RiskLevel.CRITICAL,
                vulnerability_types=["command_injection"],
                unsafe_patterns=[
                    r'os\.system\s*\(\s*[^"\']*\w+[^"\']*',  # Variable command
                    r'os\.system\s*\(\s*f"[^"]*{[^}]*}',  # f-string with variables
                ],
                safe_patterns=[
                    r'subprocess\.run\s*\(\s*\[',  # List form (safer)
                    r'os\.system\s*\(\s*"[^"{}]*"',  # Literal string only
                ],
                context_requirements=["use_subprocess_list", "input_validation"],
                description="Shell command execution - command injection risk"
            ),
            
            VulnerabilityPattern(
                function_name="pickle.loads",
                language=Language.PYTHON,
                base_risk=RiskLevel.CRITICAL,
                vulnerability_types=["deserialization", "code_execution"],
                unsafe_patterns=[
                    r'pickle\.loads\s*\(\s*\w+',  # Any pickle.loads usage
                ],
                safe_patterns=[
                    r'json\.loads',  # Use JSON instead
                ],
                context_requirements=["use_json", "input_validation"],
                description="Object deserialization - arbitrary code execution risk"
            ),
            
            VulnerabilityPattern(
                function_name="subprocess.call",
                language=Language.PYTHON,
                base_risk=RiskLevel.HIGH,
                vulnerability_types=["command_injection"],
                unsafe_patterns=[
                    r'subprocess\.call\s*\(\s*[^"\']*\w+[^"\']*',  # String with variables
                    r'subprocess\.call\s*\(\s*f"[^"]*{[^}]*}',  # f-string
                ],
                safe_patterns=[
                    r'subprocess\.call\s*\(\s*\[',  # List form
                ],
                context_requirements=["use_list_form", "input_validation"],
                description="Subprocess execution - command injection risk with shell=True"
            ),
        ]        
  
      # JavaScript Language Vulnerabilities
        js_vulns = [
            VulnerabilityPattern(
                function_name="eval",
                language=Language.JAVASCRIPT,
                base_risk=RiskLevel.CRITICAL,
                vulnerability_types=["code_injection", "xss"],
                unsafe_patterns=[
                    r'eval\s*\(\s*\w+',  # Variable input
                    r'eval\s*\(\s*.*\+.*\)',  # String concatenation
                ],
                safe_patterns=[
                    r'JSON\.parse',  # Use JSON.parse instead
                ],
                context_requirements=["use_json_parse", "input_validation"],
                description="Dynamic code execution - XSS and code injection risk"
            ),
            
            VulnerabilityPattern(
                function_name="innerHTML",
                language=Language.JAVASCRIPT,
                base_risk=RiskLevel.HIGH,
                vulnerability_types=["xss", "dom_manipulation"],
                unsafe_patterns=[
                    r'\.innerHTML\s*=\s*\w+',  # Variable content
                    r'\.innerHTML\s*=\s*.*\+.*',  # String concatenation
                ],
                safe_patterns=[
                    r'\.textContent\s*=',  # Use textContent instead
                    r'\.innerHTML\s*=\s*"[^"]*"',  # Literal string
                ],
                context_requirements=["use_textContent", "html_sanitization"],
                description="DOM manipulation with unsanitized content - XSS risk"
            ),
            
            VulnerabilityPattern(
                function_name="document.write",
                language=Language.JAVASCRIPT,
                base_risk=RiskLevel.HIGH,
                vulnerability_types=["xss"],
                unsafe_patterns=[
                    r'document\.write\s*\(\s*\w+',  # Variable content
                ],
                safe_patterns=[
                    r'document\.createElement',  # DOM manipulation instead
                ],
                context_requirements=["use_dom_methods", "content_sanitization"],
                description="Direct document writing - XSS risk"
            ),
            
            VulnerabilityPattern(
                function_name="setTimeout",
                language=Language.JAVASCRIPT,
                base_risk=RiskLevel.HIGH,
                vulnerability_types=["code_injection"],
                unsafe_patterns=[
                    r'setTimeout\s*\(\s*\w+\s*,',  # Variable code string
                    r'setTimeout\s*\(\s*"[^"]*"\s*\+\s*\w+',  # String concatenation
                ],
                safe_patterns=[
                    r'setTimeout\s*\(\s*function\s*\(',  # Function reference
                    r'setTimeout\s*\(\s*\(\s*\)\s*=>',  # Arrow function
                ],
                context_requirements=["use_function_reference"],
                description="Dynamic code execution in timer - code injection risk"
            ),
        ]
        
        # Go Language Vulnerabilities
        go_vulns = [
            VulnerabilityPattern(
                function_name="os/exec.Command",
                language=Language.GO,
                base_risk=RiskLevel.HIGH,
                vulnerability_types=["command_injection"],
                unsafe_patterns=[
                    r'exec\.Command\s*\(\s*\w+',  # Variable command
                    r'exec\.Command\s*\(\s*"[^"]*"\s*,\s*\w+',  # Variable args
                ],
                safe_patterns=[
                    r'exec\.Command\s*\(\s*"[^"]*"\s*,\s*"[^"]*"',  # All literals
                ],
                context_requirements=["input_validation", "command_whitelist"],
                description="Command execution - command injection risk"
            ),
            
            VulnerabilityPattern(
                function_name="fmt.Sprintf",
                language=Language.GO,
                base_risk=RiskLevel.MEDIUM,
                vulnerability_types=["format_string"],
                unsafe_patterns=[
                    r'fmt\.Sprintf\s*\(\s*\w+',  # Variable format
                ],
                safe_patterns=[
                    r'fmt\.Sprintf\s*\(\s*"[^"]*"',  # Literal format
                ],
                context_requirements=["literal_format"],
                description="Formatted string with variable format - format string risk"
            ),
            
            VulnerabilityPattern(
                function_name="unsafe.Pointer",
                language=Language.GO,
                base_risk=RiskLevel.HIGH,
                vulnerability_types=["memory_corruption", "type_confusion"],
                unsafe_patterns=[
                    r'unsafe\.Pointer\s*\(',
                ],
                safe_patterns=[],  # Generally should be avoided
                context_requirements=["expert_review"],
                description="Unsafe pointer operations - memory corruption risk"
            ),
        ]
        
        # Build database by function name
        all_patterns = c_vulns + cpp_vulns + java_vulns + python_vulns + js_vulns + go_vulns
        
        for pattern in all_patterns:
            if pattern.function_name not in db:
                db[pattern.function_name] = []
            db[pattern.function_name].append(pattern)
        
        return db    

    def _build_language_detectors(self) -> Dict[Language, List[str]]:
        """Build language detection patterns"""
        return {
            Language.C: ['#include', 'void', 'int main', 'char*', 'malloc', 'free'],
            Language.CPP: ['#include', 'std::', 'namespace', 'class', 'new', 'delete'],
            Language.JAVA: ['public class', 'import java', 'public static void main', 'System.'],
            Language.PYTHON: ['def ', 'import ', 'if __name__', 'print(', '.py'],
            Language.JAVASCRIPT: ['function', 'var ', 'let ', 'const ', 'document.', 'window.'],
            Language.GO: ['package ', 'import ', 'func ', 'go ', 'fmt.']
        }
    
    def detect_language(self, source_code: str) -> Language:
        """Detect programming language from source code"""
        
        code_lower = source_code.lower()
        language_scores = {}
        
        for language, patterns in self.language_detectors.items():
            score = sum(1 for pattern in patterns if pattern.lower() in code_lower)
            language_scores[language] = score
        
        # Return language with highest score
        if language_scores:
            detected_language = max(language_scores, key=language_scores.get)
            if language_scores[detected_language] > 0:
                return detected_language
        
        return Language.C  # Default fallback
    
    def analyze_function_in_context(self, function_name: str, line_content: str, 
                                  context_lines: List[str], language: Language) -> Dict:
        """
        Analyze a function call in its context to determine actual risk.
        
        This is the KEY IMPROVEMENT that solves the false positive problem.
        """
        
        # Get patterns for this function
        if function_name not in self.vulnerability_db:
            return {'risk_score': 0.1, 'is_safe_usage': True, 'explanation': 'Unknown function'}
        
        patterns = [p for p in self.vulnerability_db[function_name] if p.language == language]
        if not patterns:
            return {'risk_score': 0.1, 'is_safe_usage': True, 'explanation': 'Function not risky in this language'}
        
        pattern = patterns[0]  # Use first matching pattern
        base_risk = pattern.base_risk.value
        
        # Check for unsafe patterns
        unsafe_detected = any(re.search(unsafe_pattern, line_content) for unsafe_pattern in pattern.unsafe_patterns)
        
        # Check for safe patterns (KEY IMPROVEMENT)
        safe_detected = any(re.search(safe_pattern, line_content) for safe_pattern in pattern.safe_patterns)
        
        # Check context for safety mitigations
        context_text = ' '.join(context_lines)
        context_safety = 0
        
        for requirement in pattern.context_requirements:
            if self._check_safety_requirement(requirement, line_content, context_text):
                context_safety += 0.2
        
        # Calculate final risk score
        if safe_detected:
            # Safe pattern detected - significantly reduce risk
            risk_score = base_risk * 0.05  # 95% risk reduction
            is_safe_usage = True
            explanation = f"Safe usage of {function_name} detected"
        elif unsafe_detected:
            # Unsafe pattern detected - full risk
            risk_score = base_risk
            is_safe_usage = False
            explanation = f"Unsafe usage of {function_name} - {pattern.description}"
        else:
            # No specific pattern - check if it's inherently safe function like snprintf
            if function_name in ['snprintf', 'strncpy', 'strncat'] and context_safety > 0.2:
                # These functions are generally safe when used properly
                risk_score = base_risk * 0.1
                is_safe_usage = True
                explanation = f"Safe usage of {function_name} detected"
            else:
                # Moderate risk with context adjustment
                risk_score = base_risk * (1.0 - min(context_safety, 0.8))
                is_safe_usage = context_safety > 0.4
                explanation = f"Context-dependent usage of {function_name}"
        
        return {
            'risk_score': risk_score,
            'is_safe_usage': is_safe_usage,
            'explanation': explanation,
            'vulnerability_types': pattern.vulnerability_types,
            'base_risk': base_risk,
            'context_safety': context_safety,
            'safe_pattern_detected': safe_detected,
            'unsafe_pattern_detected': unsafe_detected
        }
    
    def _check_safety_requirement(self, requirement: str, line_content: str, context: str) -> bool:
        """Check if a safety requirement is met"""
        
        safety_checks = {
            'bounds_check': [
                r'if\s*\([^)]*len[^)]*<[^)]*\)',
                r'if\s*\([^)]*size[^)]*<[^)]*\)',
                r'strlen\s*\([^)]+\)\s*<\s*sizeof',
            ],
            'size_validation': [
                r'sizeof\s*\(',
                r'strlen\s*\(',
                r'if\s*\([^)]*\d+[^)]*\)',
            ],
            'null_termination': [
                r'\w+\[\w*\]\s*=\s*[\'"]\\0[\'"]',
                r'\w+\[\w*\]\s*=\s*0',
            ],
            'literal_format': [
                r'"[^"]*%[sd][^"]*"',  # Literal format string with placeholders
                r'"[^"]*"[^+]*$',  # Literal string not concatenated
            ],
            'input_validation': [
                r'if\s*\([^)]*!=\s*NULL\)',
                r'if\s*\([^)]*==\s*NULL\)',
                r'validate\s*\(',
                r'sanitize\s*\(',
            ],
            'use_safe_alternative': [
                r'strncpy',
                r'snprintf',
                r'strncat',
            ],
            'use_textContent': [
                r'\.textContent\s*=',
            ],
            'html_sanitization': [
                r'sanitize\s*\(',
                r'escape\s*\(',
            ],
            'use_dom_methods': [
                r'document\.createElement',
                r'appendChild',
            ],
            'content_sanitization': [
                r'sanitize\s*\(',
                r'validate\s*\(',
            ],
            'use_function_reference': [
                r'function\s*\(',
                r'\(\s*\)\s*=>',
            ],
            'command_whitelist': [
                r'whitelist',
                r'allowed_commands',
            ],
            'expert_review': [
                r'//.*expert',
                r'//.*review',
            ]
        }
        
        if requirement in safety_checks:
            patterns = safety_checks[requirement]
            return any(re.search(pattern, line_content + ' ' + context, re.IGNORECASE) 
                      for pattern in patterns)
        
        return False 
   
    def get_all_dangerous_functions(self, language: Language = None) -> List[str]:
        """Get list of all dangerous functions, optionally filtered by language"""
        
        if language is None:
            return list(self.vulnerability_db.keys())
        
        functions = set()
        for function_name, patterns in self.vulnerability_db.items():
            if any(p.language == language for p in patterns):
                functions.add(function_name)
        
        return sorted(list(functions))
    
    def get_vulnerability_summary(self) -> Dict:
        """Get summary statistics of the vulnerability database"""
        
        summary = {
            'total_functions': len(self.vulnerability_db),
            'by_language': {},
            'by_risk_level': {},
            'by_vulnerability_type': {}
        }
        
        for language in Language:
            summary['by_language'][language.value] = len(self.get_all_dangerous_functions(language))
        
        for patterns in self.vulnerability_db.values():
            for pattern in patterns:
                risk_level = pattern.base_risk.name
                summary['by_risk_level'][risk_level] = summary['by_risk_level'].get(risk_level, 0) + 1
                
                for vuln_type in pattern.vulnerability_types:
                    summary['by_vulnerability_type'][vuln_type] = summary['by_vulnerability_type'].get(vuln_type, 0) + 1
        
        return summary


class EnhancedVulnerabilityPatternDetector:
    """
    Enhanced pattern detector that uses the comprehensive database
    and provides context-aware analysis.
    
    This is the SOLUTION to our false positive problem.
    """
    
    def __init__(self):
        self.db = ComprehensiveVulnerabilityDatabase()
        print(f"🔧 Enhanced Pattern Detector initialized with {len(self.db.vulnerability_db)} dangerous functions")
        
        # Print summary
        summary = self.db.get_vulnerability_summary()
        print(f"📊 Database Summary:")
        for lang, count in summary['by_language'].items():
            print(f"   {lang.upper()}: {count} functions")
    
    def analyze_source_code(self, source_code: str, context_window: int = 3) -> Dict:
        """
        Analyze entire source code for vulnerabilities with context awareness.
        
        This replaces the old annotate_vulnerable_lines method.
        """
        
        lines = source_code.split('\n')
        language = self.db.detect_language(source_code)
        
        print(f"🔍 Analyzing {len(lines)} lines in {language.value.upper()}...")
        
        results = {
            'language': language,
            'total_lines': len(lines),
            'vulnerable_lines': {},
            'safe_lines': {},
            'function_analysis': {},
            'overall_risk_score': 0.0,
            'recommendations': []
        }
        
        dangerous_functions = self.db.get_all_dangerous_functions(language)
        
        for line_num, line in enumerate(lines):
            line_stripped = line.strip()
            if not line_stripped or line_stripped.startswith('//') or line_stripped.startswith('#'):
                continue
            
            # Get context lines
            start_idx = max(0, line_num - context_window)
            end_idx = min(len(lines), line_num + context_window + 1)
            context_lines = [lines[i].strip() for i in range(start_idx, end_idx) if i != line_num]
            
            # Check for dangerous functions
            for func_name in dangerous_functions:
                if func_name in line_stripped:
                    # Analyze this function in context
                    analysis = self.db.analyze_function_in_context(
                        func_name, line_stripped, context_lines, language
                    )
                    
                    # Store analysis
                    if func_name not in results['function_analysis']:
                        results['function_analysis'][func_name] = []
                    
                    analysis['line_number'] = line_num
                    analysis['line_content'] = line_stripped
                    results['function_analysis'][func_name].append(analysis)
                    
                    # Categorize line
                    if analysis['is_safe_usage']:
                        results['safe_lines'][line_num] = {
                            'score': analysis['risk_score'],
                            'function': func_name,
                            'explanation': analysis['explanation']
                        }
                    else:
                        results['vulnerable_lines'][line_num] = {
                            'score': analysis['risk_score'],
                            'function': func_name,
                            'explanation': analysis['explanation'],
                            'vulnerability_types': analysis['vulnerability_types']
                        }
        
        # Calculate overall risk
        if results['vulnerable_lines']:
            results['overall_risk_score'] = max(v['score'] for v in results['vulnerable_lines'].values())
        
        # Generate recommendations
        results['recommendations'] = self._generate_recommendations(results)
        
        print(f"✅ Analysis complete:")
        print(f"   Vulnerable lines: {len(results['vulnerable_lines'])}")
        print(f"   Safe lines: {len(results['safe_lines'])}")
        print(f"   Overall risk: {results['overall_risk_score']:.2f}")
        
        return results
    
    def _generate_recommendations(self, analysis_results: Dict) -> List[str]:
        """Generate specific recommendations based on analysis"""
        
        recommendations = []
        
        # Function-specific recommendations
        for func_name, analyses in analysis_results['function_analysis'].items():
            unsafe_usages = [a for a in analyses if not a['is_safe_usage']]
            
            if unsafe_usages:
                if func_name == 'strcpy':
                    recommendations.append(f"Replace strcpy() with strncpy() and add bounds checking")
                elif func_name == 'sprintf':
                    recommendations.append(f"Replace sprintf() with snprintf() with buffer size limits")
                elif func_name == 'gets':
                    recommendations.append(f"Replace gets() with fgets() - gets() is inherently unsafe")
                elif func_name == 'eval':
                    recommendations.append(f"Avoid eval() with user input - use safer alternatives like JSON.parse")
                elif func_name == 'exec':
                    recommendations.append(f"Validate and sanitize all inputs to exec() functions")
        
        # General recommendations
        if analysis_results['overall_risk_score'] > 0.8:
            recommendations.append("🚨 CRITICAL: Multiple high-risk vulnerabilities detected - immediate review required")
        elif analysis_results['overall_risk_score'] > 0.6:
            recommendations.append("⚠️ HIGH: Security vulnerabilities present - schedule review within 24 hours")
        
        return recommendations


# Test function
def test_enhanced_database():
    """Test the enhanced vulnerability database"""
    
    print("🧪 Testing Enhanced Vulnerability Database")
    print("="*60)
    
    detector = EnhancedVulnerabilityPatternDetector()
    
    # Test C code with safe and unsafe patterns
    test_code = '''
void test_function(char* input) {
    char buffer[64];
    
    // Unsafe usage
    strcpy(buffer, input);
    
    // Safe usage
    if (strlen(input) < sizeof(buffer) - 1) {
        strncpy(buffer, input, sizeof(buffer) - 1);
        buffer[sizeof(buffer) - 1] = '\\0';
    }
    
    // Format string vulnerability
    printf(buffer);
    
    // Safe printf
    printf("%s\\n", buffer);
}
'''
    
    results = detector.analyze_source_code(test_code)
    
    print(f"\n📊 Test Results:")
    print(f"Language detected: {results['language'].value}")
    print(f"Vulnerable lines: {len(results['vulnerable_lines'])}")
    print(f"Safe lines: {len(results['safe_lines'])}")
    
    for line_num, info in results['vulnerable_lines'].items():
        print(f"  VULNERABLE Line {line_num}: {info['function']} - {info['explanation']}")
    
    for line_num, info in results['safe_lines'].items():
        print(f"  SAFE Line {line_num}: {info['function']} - {info['explanation']}")
    
    print(f"\n💡 Recommendations:")
    for rec in results['recommendations']:
        print(f"  • {rec}")


if __name__ == "__main__":
    test_enhanced_database()