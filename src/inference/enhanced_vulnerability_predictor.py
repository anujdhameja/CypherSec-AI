#!/usr/bin/env python3
"""
Enhanced Vulnerability Predictor with Context-Aware Pattern Detection

This module combines the trained GNN model with our enhanced context-aware
pattern detection system to provide more accurate vulnerability predictions
with detailed explanations and reduced false positives.

Key Features:
- GNN model predictions
- Context-aware pattern analysis
- Multi-language vulnerability detection
- Detailed explanations with line-level analysis
- False positive reduction through context awareness
"""

import torch
import sys
import os
from pathlib import Path
from typing import Dict, List, Optional, Tuple

# Add src to path
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

from src.inference.predict_vulnerabilities import VulnerabilityPredictor
from src.process.vulnerability_pattern_detector import VulnerabilityPatternDetector
from torch_geometric.data import Data
import numpy as np


class EnhancedVulnerabilityPredictor(VulnerabilityPredictor):
    """
    Enhanced vulnerability predictor that combines GNN predictions with
    context-aware pattern analysis for improved accuracy and explanations.
    """
    
    def __init__(self, model_path='models/final_model.pth', w2v_path='data/w2v/w2v.model'):
        # Initialize base predictor
        super().__init__(model_path, w2v_path)
        
        # Initialize enhanced pattern detector
        print("ðŸš€ Initializing Enhanced Context-Aware Pattern Detection...")
        self.pattern_detector = VulnerabilityPatternDetector(use_enhanced=True)
        
        print("âœ… Enhanced Vulnerability Predictor ready!")
        print("   - GNN model predictions")
        print("   - Context-aware pattern analysis")
        print("   - Multi-language support")
        print("   - Detailed explanations")
        print("="*60 + "\n")
    
    def predict_with_source_code(self, graph_data: Data, source_code: str, 
                                node_to_line_mapping: Optional[Dict[int, int]] = None) -> Dict:
        """
        Enhanced prediction that combines GNN model with context-aware pattern analysis.
        
        Args:
            graph_data: PyTorch Geometric Data object
            source_code: Original source code string
            node_to_line_mapping: Optional mapping from node indices to line numbers
            
        Returns:
            Enhanced prediction result with pattern analysis and explanations
        """
        
        # Get base GNN prediction
        gnn_result = self.predict(graph_data)
        
        # Get context-aware pattern analysis
        print("ðŸ” Performing context-aware pattern analysis...")
        pattern_analysis = self.pattern_detector.enhanced_detector.get_detailed_analysis(source_code)
        
        # Get vulnerable line annotations
        vulnerable_lines = self.pattern_detector.annotate_vulnerable_lines(source_code)
        
        # Create enhanced result
        enhanced_result = {
            # Base GNN prediction
            'gnn_prediction': gnn_result,
            
            # Pattern analysis results
            'pattern_analysis': {
                'language': pattern_analysis['language'].value,
                'total_lines': pattern_analysis['total_lines'],
                'vulnerable_lines': len(pattern_analysis['vulnerable_lines']),
                'safe_lines': len(pattern_analysis['safe_lines']),
                'overall_risk_score': pattern_analysis['overall_risk_score'],
                'vulnerable_line_details': pattern_analysis['vulnerable_lines'],
                'safe_line_details': pattern_analysis['safe_lines'],
                'recommendations': pattern_analysis['recommendations']
            },
            
            # Combined assessment
            'combined_assessment': self._combine_predictions(gnn_result, pattern_analysis, vulnerable_lines),
            
            # Detailed explanations
            'explanations': self._generate_explanations(source_code, vulnerable_lines, pattern_analysis),
            
            # Source code analysis
            'source_analysis': {
                'total_lines': len(source_code.split('\n')),
                'vulnerable_line_numbers': list(vulnerable_lines.keys()),
                'vulnerability_scores': vulnerable_lines
            }
        }
        
        return enhanced_result
    
    def _combine_predictions(self, gnn_result: Dict, pattern_analysis: Dict, vulnerable_lines: Dict) -> Dict:
        """
        Combine GNN model prediction with pattern analysis for final assessment.
        
        Args:
            gnn_result: Result from GNN model
            pattern_analysis: Result from pattern analysis
            vulnerable_lines: Vulnerable line annotations
            
        Returns:
            Combined assessment with confidence weighting
        """
        
        gnn_vulnerable = gnn_result['is_vulnerable']
        gnn_confidence = gnn_result['confidence']
        
        pattern_vulnerable = len(vulnerable_lines) > 0
        pattern_confidence = pattern_analysis['overall_risk_score']
        
        # Weighted combination (GNN gets 60% weight, patterns get 40%)
        gnn_weight = 0.6
        pattern_weight = 0.4
        
        if gnn_vulnerable and pattern_vulnerable:
            # Both agree on vulnerable
            final_vulnerable = True
            final_confidence = gnn_weight * gnn_confidence + pattern_weight * pattern_confidence
            agreement = "Both GNN and pattern analysis agree: VULNERABLE"
            
        elif not gnn_vulnerable and not pattern_vulnerable:
            # Both agree on safe
            final_vulnerable = False
            final_confidence = gnn_weight * gnn_confidence + pattern_weight * (1.0 - pattern_confidence)
            agreement = "Both GNN and pattern analysis agree: SAFE"
            
        elif gnn_vulnerable and not pattern_vulnerable:
            # GNN says vulnerable, patterns say safe
            final_vulnerable = gnn_confidence > 0.7  # High confidence threshold
            final_confidence = gnn_confidence * 0.8  # Reduce confidence due to disagreement
            agreement = "DISAGREEMENT: GNN says vulnerable, patterns say safe"
            
        else:
            # GNN says safe, patterns say vulnerable
            final_vulnerable = pattern_confidence > 0.8  # High confidence threshold for patterns
            final_confidence = pattern_confidence * 0.8  # Reduce confidence due to disagreement
            agreement = "DISAGREEMENT: GNN says safe, patterns say vulnerable"
        
        return {
            'is_vulnerable': final_vulnerable,
            'confidence': min(final_confidence, 1.0),
            'gnn_prediction': gnn_vulnerable,
            'gnn_confidence': gnn_confidence,
            'pattern_prediction': pattern_vulnerable,
            'pattern_confidence': pattern_confidence,
            'agreement_status': agreement,
            'prediction_method': 'Enhanced (GNN + Context-Aware Patterns)'
        }
    
    def _generate_explanations(self, source_code: str, vulnerable_lines: Dict, pattern_analysis: Dict) -> Dict:
        """
        Generate detailed explanations for the vulnerability assessment.
        
        Args:
            source_code: Original source code
            vulnerable_lines: Vulnerable line annotations
            pattern_analysis: Pattern analysis results
            
        Returns:
            Detailed explanations dictionary
        """
        
        lines = source_code.split('\n')
        explanations = {
            'summary': '',
            'line_explanations': {},
            'recommendations': pattern_analysis['recommendations'],
            'language_detected': pattern_analysis['language'].value
        }
        
        # Generate line-by-line explanations
        for line_num, score in vulnerable_lines.items():
            if line_num < len(lines):
                line_content = lines[line_num].strip()
                explanation = self.pattern_detector.explain_vulnerability_pattern(
                    line_content, score, source_code
                )
                explanations['line_explanations'][line_num] = {
                    'line_content': line_content,
                    'vulnerability_score': score,
                    'explanation': explanation
                }
        
        # Generate summary
        if vulnerable_lines:
            max_score = max(vulnerable_lines.values())
            num_vulnerable = len(vulnerable_lines)
            explanations['summary'] = (
                f"Found {num_vulnerable} potentially vulnerable lines in {pattern_analysis['language'].value.upper()} code. "
                f"Highest risk score: {max_score:.2f}. "
                f"Context-aware analysis detected {len(pattern_analysis['safe_lines'])} safe usage patterns."
            )
        else:
            explanations['summary'] = (
                f"No vulnerable patterns detected in {pattern_analysis['language'].value.upper()} code. "
                f"Context-aware analysis confirmed {len(pattern_analysis['safe_lines'])} safe usage patterns."
            )
        
        return explanations
    
    def print_enhanced_prediction(self, result: Dict, graph_info: str = ""):
        """Pretty print enhanced prediction result with detailed analysis"""
        
        print("\n" + "="*80)
        print("ðŸš€ ENHANCED VULNERABILITY PREDICTION RESULT")
        print("="*80)
        
        if graph_info:
            print(f"Graph: {graph_info}")
        
        # Combined assessment
        combined = result['combined_assessment']
        status = "ðŸš¨ VULNERABLE" if combined['is_vulnerable'] else "âœ… SAFE"
        print(f"\nðŸŽ¯ FINAL ASSESSMENT: {status}")
        print(f"   Confidence: {combined['confidence']:.2%}")
        print(f"   Method: {combined['prediction_method']}")
        print(f"   Agreement: {combined['agreement_status']}")
        
        # Pattern analysis summary
        pattern = result['pattern_analysis']
        print(f"\nðŸ” PATTERN ANALYSIS:")
        print(f"   Language: {pattern['language'].upper()}")
        print(f"   Total lines: {pattern['total_lines']}")
        print(f"   Vulnerable lines: {pattern['vulnerable_lines']}")
        print(f"   Safe usage detected: {pattern['safe_lines']}")
        print(f"   Overall risk score: {pattern['overall_risk_score']:.2f}")
        
        # GNN model results
        gnn = result['gnn_prediction']
        print(f"\nðŸ¤– GNN MODEL:")
        print(f"   Prediction: {'Vulnerable' if gnn['is_vulnerable'] else 'Safe'}")
        print(f"   Confidence: {gnn['confidence']:.2%}")
        print(f"   Prob Safe: {gnn['prob_safe']:.2%}")
        print(f"   Prob Vulnerable: {gnn['prob_vulnerable']:.2%}")
        
        # Detailed explanations
        explanations = result['explanations']
        print(f"\nðŸ’¡ EXPLANATIONS:")
        print(f"   {explanations['summary']}")
        
        if explanations['line_explanations']:
            print(f"\nðŸ“‹ LINE-BY-LINE ANALYSIS:")
            for line_num, details in explanations['line_explanations'].items():
                print(f"   Line {line_num:2d}: {details['explanation']}")
                print(f"           Code: {details['line_content']}")
                print(f"           Risk: {details['vulnerability_score']:.2f}")
        
        # Recommendations
        if explanations['recommendations']:
            print(f"\nðŸ”§ RECOMMENDATIONS:")
            for rec in explanations['recommendations']:
                print(f"   â€¢ {rec}")
        
        print("="*80 + "\n")


def test_enhanced_predictor():
    """Test the enhanced predictor with real source code examples"""
    
    print("ðŸ§ª Testing Enhanced Vulnerability Predictor")
    print("="*80)
    
    try:
        # Initialize enhanced predictor
        predictor = EnhancedVulnerabilityPredictor()
        
        # Test Case 1: Vulnerable C code
        print("\nðŸ“‹ TEST CASE 1: VULNERABLE C CODE")
        print("-" * 50)
        
        vulnerable_code = '''
void process_user_input(char* user_data) {
    char buffer[64];
    char temp[32];
    
    // Unsafe operations
    strcpy(buffer, user_data);
    strcat(buffer, "_processed");
    sprintf(temp, buffer);
    printf(temp);
    
    return;
}
'''
        
        # Create dummy graph for this code
        graph1 = create_test_graph(10, complex=True)
        result1 = predictor.predict_with_source_code(graph1, vulnerable_code)
        predictor.print_enhanced_prediction(result1, "Vulnerable C Code")
        
        # Test Case 2: Safe C code
        print("\nðŸ“‹ TEST CASE 2: SAFE C CODE")
        print("-" * 50)
        
        safe_code = '''
void process_user_input_safe(char* user_data) {
    char buffer[128];
    
    // Safe operations with bounds checking
    if (user_data != NULL && strlen(user_data) < sizeof(buffer) - 10) {
        strncpy(buffer, user_data, sizeof(buffer) - 10);
        buffer[sizeof(buffer) - 1] = '\\0';
        strncat(buffer, "_processed", 9);
        printf("%s\\n", buffer);
    }
    
    return;
}
'''
        
        # Create dummy graph for this code
        graph2 = create_test_graph(8, complex=False)
        result2 = predictor.predict_with_source_code(graph2, safe_code)
        predictor.print_enhanced_prediction(result2, "Safe C Code")
        
        # Test Case 3: Mixed safe and unsafe
        print("\nðŸ“‹ TEST CASE 3: MIXED SAFE AND UNSAFE CODE")
        print("-" * 50)
        
        mixed_code = '''
void mixed_function(char* input) {
    char safe_buffer[100];
    char unsafe_buffer[50];
    
    // Safe usage
    if (strlen(input) < 99) {
        strncpy(safe_buffer, input, 99);
        safe_buffer[99] = '\\0';
        printf("Safe: %s\\n", safe_buffer);
    }
    
    // Unsafe usage
    strcpy(unsafe_buffer, input);
    printf(unsafe_buffer);
}
'''
        
        # Create dummy graph for this code
        graph3 = create_test_graph(12, complex=True)
        result3 = predictor.predict_with_source_code(graph3, mixed_code)
        predictor.print_enhanced_prediction(result3, "Mixed Safe/Unsafe Code")
        
        print("âœ… Enhanced predictor testing completed!")
        
    except Exception as e:
        print(f"âŒ Test failed: {e}")
        import traceback
        traceback.print_exc()


def create_test_graph(num_nodes: int, complex: bool = False) -> Data:
    """Create a test graph for demonstration"""
    
    # Node features (random for demo)
    x = torch.randn(num_nodes, 100)
    
    # Edge connectivity
    edges = []
    
    # Basic chain
    for i in range(num_nodes - 1):
        edges.extend([[i, i+1], [i+1, i]])
    
    if complex:
        # Add complex connections for "vulnerable" patterns
        edges.extend([
            [0, num_nodes//2], [num_nodes//2, 0],
            [1, num_nodes-1], [num_nodes-1, 1],
            [2, num_nodes//3], [num_nodes//3, 2],
        ])
    
    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()
    return Data(x=x, edge_index=edge_index)


if __name__ == "__main__":
    test_enhanced_predictor()