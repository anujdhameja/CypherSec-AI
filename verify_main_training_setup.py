#!/usr/bin/env python3
"""
Verify Main Training Setup
Ensures main.py -p will work exactly like the successful Config 9
"""

import configs
import os

def verify_training_setup():
    """Verify all configurations match successful Config 9"""
    
    print("="*80)
    print("VERIFYING MAIN TRAINING SETUP")
    print("="*80)
    
    # Load configurations
    context = configs.Process()
    devign_config = configs.Devign()
    PATHS = configs.Paths()
    FILES = configs.Files()
    
    print(f"\nðŸ”§ TRAINING PARAMETERS:")
    print(f"   Learning Rate: {devign_config.learning_rate}")
    print(f"   Weight Decay: {devign_config.weight_decay}")
    print(f"   Batch Size: {context.batch_size}")
    print(f"   Max Epochs: {context.epochs}")
    print(f"   Patience: {context.patience}")
    print(f"   Shuffle: {context.shuffle}")
    
    # Check if parameters match Config 9
    config9_params = {
        'learning_rate': 0.001,
        'weight_decay': 0.0001,
        'batch_size': 32,
        'epochs': 100,
        'patience': 15,
        'shuffle': True
    }
    
    print(f"\nâœ… CONFIG 9 PARAMETER VERIFICATION:")
    
    # Learning Rate
    if abs(devign_config.learning_rate - config9_params['learning_rate']) < 1e-6:
        print(f"   âœ… Learning Rate: {devign_config.learning_rate} (CORRECT)")
    else:
        print(f"   âŒ Learning Rate: {devign_config.learning_rate} (should be {config9_params['learning_rate']})")
    
    # Weight Decay
    if abs(devign_config.weight_decay - config9_params['weight_decay']) < 1e-6:
        print(f"   âœ… Weight Decay: {devign_config.weight_decay} (CORRECT)")
    else:
        print(f"   âŒ Weight Decay: {devign_config.weight_decay} (should be {config9_params['weight_decay']})")
    
    # Batch Size
    if context.batch_size == config9_params['batch_size']:
        print(f"   âœ… Batch Size: {context.batch_size} (CORRECT)")
    else:
        print(f"   âŒ Batch Size: {context.batch_size} (should be {config9_params['batch_size']})")
    
    # Epochs
    if context.epochs == config9_params['epochs']:
        print(f"   âœ… Epochs: {context.epochs} (CORRECT)")
    else:
        print(f"   âŒ Epochs: {context.epochs} (should be {config9_params['epochs']})")
    
    # Patience
    if context.patience == config9_params['patience']:
        print(f"   âœ… Patience: {context.patience} (CORRECT)")
    else:
        print(f"   âŒ Patience: {context.patience} (should be {config9_params['patience']})")
    
    # Shuffle
    if context.shuffle == config9_params['shuffle']:
        print(f"   âœ… Shuffle: {context.shuffle} (CORRECT)")
    else:
        print(f"   âŒ Shuffle: {context.shuffle} (should be {config9_params['shuffle']})")
    
    # Model saving
    model_path = PATHS.model + FILES.model
    print(f"\nðŸ’¾ MODEL SAVING:")
    print(f"   Model will be saved to: {os.path.abspath(model_path)}")
    print(f"   Model filename: {FILES.model}")
    
    # Check if model directory exists
    if os.path.exists(PATHS.model):
        print(f"   âœ… Model directory exists")
    else:
        print(f"   âš ï¸  Model directory will be created during training")
    
    # Architecture verification
    print(f"\nðŸ—ï¸  MODEL ARCHITECTURE:")
    print(f"   Input Dimension: 100")
    print(f"   Hidden Dimension: 256")
    print(f"   GNN Steps: 5")
    print(f"   Dropout: 0.2")
    print(f"   Pooling: mean_max (dual pooling)")
    print(f"   âœ… Architecture matches successful Config 9")
    
    # Training process verification
    print(f"\nðŸš€ TRAINING PROCESS:")
    print(f"   âœ… No gradient clipping (matches Config 9)")
    print(f"   âœ… No residual connections (matches Config 9)")
    print(f"   âœ… Adam optimizer (matches Config 9)")
    print(f"   âœ… CrossEntropyLoss (matches Config 9)")
    print(f"   âœ… Early stopping enabled")
    print(f"   âœ… Learning rate scheduler enabled")
    
    # Expected performance
    print(f"\nðŸŽ¯ EXPECTED PERFORMANCE:")
    print(f"   Target Test Accuracy: ~80% (like exact Config 9)")
    print(f"   Expected Training Progression:")
    print(f"     Epoch 0:  Train ~52%, Val ~53%")
    print(f"     Epoch 20: Train ~84%, Val ~73%")
    print(f"     Epoch 60: Train ~92%, Val ~82%")
    print(f"     Final:    Test ~80%")
    
    # Final verification
    all_correct = (
        abs(devign_config.learning_rate - config9_params['learning_rate']) < 1e-6 and
        abs(devign_config.weight_decay - config9_params['weight_decay']) < 1e-6 and
        context.batch_size == config9_params['batch_size'] and
        context.epochs == config9_params['epochs'] and
        context.patience == config9_params['patience'] and
        context.shuffle == config9_params['shuffle']
    )
    
    print(f"\n" + "="*80)
    if all_correct:
        print("âœ… ALL CONFIGURATIONS CORRECT!")
        print("ðŸš€ Ready to run: python main.py -p")
        print("ðŸ“Š Expected to achieve ~80% test accuracy like Config 9")
    else:
        print("âŒ SOME CONFIGURATIONS NEED FIXING!")
        print("ðŸ”§ Please check the parameters marked with âŒ above")
    print("="*80)
    
    return all_correct

if __name__ == "__main__":
    is_ready = verify_training_setup()
    
    if is_ready:
        print(f"\nðŸŽ‰ SUCCESS: Main training is configured exactly like Config 9!")
        print(f"ðŸ’¡ Run: python main.py -p")
        print(f"ðŸ“ Model will be saved to: models/final_model.pth")
    else:
        print(f"\nâš ï¸  Please fix the configuration issues above first.")