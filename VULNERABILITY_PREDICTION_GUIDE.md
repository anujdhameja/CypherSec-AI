# Vulnerability Prediction Guide

## Stage 5: GNN Prediction - Using Your Trained Model

Your model achieved **92.96% test accuracy** and is now ready for production use!

## 🚀 Quick Start

### 1. Basic Prediction
```bash
# Run demo with synthetic examples
python predict_vulnerability.py --demo

# Test with real data from your dataset
python predict_vulnerability.py --test
```

### 2. Python API Usage
```python
from src.inference.predict_vulnerabilities import VulnerabilityPredictor
from torch_geometric.data import Data
import torch

# Initialize predictor
predictor = VulnerabilityPredictor('models/final_model.pth')

# Create or load graph data
graph_data = Data(x=node_features, edge_index=edge_connectivity)

# Make prediction
result = predictor.predict(graph_data)

print(f"Vulnerable: {result['is_vulnerable']}")
print(f"Confidence: {result['confidence']:.2%}")
```

## 📊 Model Performance

Your trained model (`final_model.pth`) achieves:

- **Test Accuracy: 92.96%** 🎉
- **Precision: 98.15%** (Very few false alarms)
- **Recall: 87.36%** (Catches most vulnerabilities)
- **F1-Score: 92.44%** (Excellent balance)
- **ROC AUC: 98.13%** (Outstanding discrimination)

## 🔧 Model Architecture

- **Input Dimension:** 100 (Word2Vec embeddings)
- **Hidden Dimension:** 256
- **GNN Steps:** 5 (message passing iterations)
- **Dropout:** 0.2
- **Pooling:** Mean + Max (dual pooling)
- **Output:** Binary classification (Safe/Vulnerable)

## 📁 Required Files

Make sure these files exist:
- `models/final_model.pth` - Your trained model ✅
- `data/w2v/w2v.model` - Word2Vec embeddings ✅

## 🎯 Prediction Output

The predictor returns a comprehensive result:

```python
{
    'is_vulnerable': 1,           # 0 = Safe, 1 = Vulnerable
    'confidence': 0.92,           # Confidence in prediction (0-1)
    'prob_safe': 0.08,           # Probability of being safe
    'prob_vulnerable': 0.92,      # Probability of being vulnerable
    'prediction_details': {
        'predicted_class': 'Vulnerable',
        'confidence_level': 'High',  # Very High/High/Medium/Low/Very Low
        'num_nodes': 15,
        'num_edges': 28,
        'raw_logits': [-2.1, 3.4]
    }
}
```

## 🛡️ Vulnerability Detection Analysis

Based on test results:

- **87.36% of vulnerabilities detected** (318 out of 364)
- **Only 6 false alarms** out of 375 safe samples
- **98.15% precision** - when it says "vulnerable", it's almost always right!

### Confidence Levels:
- **Very High (≥95%):** Extremely reliable prediction
- **High (≥85%):** Very reliable prediction  
- **Medium (≥70%):** Moderately reliable prediction
- **Low (≥55%):** Less reliable, manual review recommended
- **Very Low (<55%):** Uncertain, definitely needs manual review

## 🔄 Integration Examples

### Batch Processing
```python
# Process multiple graphs
results = predictor.predict_batch(graph_list)

for result in results:
    if result['is_vulnerable'] and result['confidence'] > 0.8:
        print(f"High-confidence vulnerability detected!")
```

### CI/CD Integration
```python
# In your CI/CD pipeline
def check_code_vulnerability(graph_data):
    result = predictor.predict(graph_data)
    
    if result['is_vulnerable'] and result['confidence'] > 0.85:
        return {
            'status': 'FAIL',
            'message': f"Vulnerability detected with {result['confidence']:.1%} confidence"
        }
    
    return {'status': 'PASS'}
```

### Real-time Analysis
```python
# For real-time code analysis
def analyze_code_snippet(code_graph):
    result = predictor.predict(code_graph)
    
    return {
        'risk_level': 'HIGH' if result['prob_vulnerable'] > 0.8 else 'LOW',
        'recommendation': 'Review required' if result['is_vulnerable'] else 'Looks safe',
        'confidence': result['confidence']
    }
```

## 🎮 Demo Examples

The demo creates two synthetic examples:

1. **Safe Code Pattern:** Simple linear structure (typical of straightforward, safe code)
2. **Vulnerable Code Pattern:** Complex interconnected structure (typical of vulnerable code with complex control flow)

## 🧪 Testing with Real Data

Use `--test` flag to validate the predictor against your actual dataset:

```bash
python predict_vulnerability.py --test
```

This will:
- Load samples from `data/input/*.pkl`
- Make predictions on first 5 samples
- Compare with ground truth labels
- Show accuracy metrics

## 🚀 Production Deployment

Your model is ready for production! Key benefits:

- **High Accuracy:** 92.96% test accuracy
- **Low False Alarms:** Only 1.85% false positive rate
- **Fast Inference:** Optimized for real-time prediction
- **Robust Architecture:** Proven Config 9 design

## 📈 Performance Monitoring

Monitor these metrics in production:
- Prediction confidence distribution
- False positive/negative rates
- Processing time per graph
- Model drift over time

## 🔧 Troubleshooting

Common issues:
- **FileNotFoundError:** Check model and Word2Vec paths
- **CUDA errors:** Model automatically uses CPU if GPU unavailable
- **Shape mismatches:** Ensure graph data has correct format
- **Memory issues:** Process graphs in smaller batches

Your vulnerability detection model is performing exceptionally well and ready for real-world deployment! 🎉